
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Module 2. Image classification &#8212; SEPAL-CEO Area Estimation 3-1-2021 documentation</title>
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="_static/alabaster.css" type="text/css" />
    <script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="&lt;no title&gt;" href="module-3.html" />
    <link rel="prev" title="Module 1. Mosaic image generation" href="module-1.html" />
   
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <div class="section" id="module-2-image-classification">
<h1>Module 2. Image classification<a class="headerlink" href="#module-2-image-classification" title="Permalink to this headline">¶</a></h1>
<p>The main goal of this Module is to construct a single-date land cover map by classification of a Landsat composite generated from Landsat images. Image classification is frequently used to map land cover, describing what the landscape is composed of (grass, trees, water, impervious surface), and to map land use, describing the organization of human systems on the landscape (farms, cities, wilderness). Learning to do image classification well is extremely important and requires experience. So here is your chance to build some experience. You will first consider the types of land cover classes you would like to map and the amount of variability within each class.</p>
<p>There are both supervised (uses human guidance including training data) and unsupervised (no human guidance) classification methods. The random forest approach used here uses training data and is thus a supervised classification method.</p>
<p>There are a number of supervised classification algorithms that can be used to assign the pixels in the image to the various map classes. One way of performing a supervised classification is to utilize a Machine Learning algorithm. Machine Learning algorithms utilize training data combined with image values to learn how to classify pixels. Using manually collected training data, these algorithms can train a classifier, and then use the relationships identified in the training process to classify the rest of the pixels in the map. The selection of image values (e.g., NDVI, elevation, etc.) used to train any statistical model should be well thought out and informed by your knowledge of the phenomenon of interest to classify your data (e.g., into forest, water, other, and clouds).</p>
<p>In this module, we will create a land cover map using supervised classification in SEPAL. We will train a random forest machine learning algorithm to predict land cover with a user generated reference data set. This data set is collected either in the field or manually through examination of remotely sensed data sources such as aerial imagery. The resulting model is then applied across the landscape. You will complete an accuracy assessment of the map output in Module 4.</p>
<p>Before starting your classification, you will need to create a response design with details about each of the land covers/land uses that you want to classify (Exercise 2.1); create mosaics for your area of interest (in Exercise 2.2 we will use a region of Brazil); and collect training data for the model (Exercise 2.3). Then, in Exercise 2.4 we will run the classification and examine our results.</p>
<p>The workflow in this module has been adapted from exercises and material developed by Dr. Pontus Olofsson, Christopher E. Holden, and Eric L. Bullock at the Boston Education in Earth Observation Data Analysis in the Department of Earth &amp; Environment, Boston University. To learn more about their materials and their work, visit their github site at <a class="reference external" href="https://github.com/beeoda">https://github.com/beeoda</a>.</p>
<p>At the end of this module you will have a classified land use land cover map.</p>
<p>This module takes approximately 4 hours to complete.</p>
<div class="section" id="exercise-2-1-response-design-for-classification">
<h2>Exercise 2.1. Response design for classification<a class="headerlink" href="#exercise-2-1-response-design-for-classification" title="Permalink to this headline">¶</a></h2>
<p>Creating consistent labelling protocols is necessary for creating accurate training data and later, accurate sample based estimates (see Module 4). They are especially important when more than one researcher is working on a project and for reproducible data collection. Response design helps a user assign a land cover / land use class to a spatial point. The response design is part of the metadata for the assessment and should contain the information necessary to reproduce the data collection. The response design lays out an objective procedure that interpreters can follow and that reduces interpreter bias.</p>
<p>In this exercise, you will build a decision tree for your classification along with much of the other documentation and decision points (for more on decision points, please see Module 5, Exercise 5.1).</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 56%" />
<col style="width: 44%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Objectives</p></th>
<th class="head"><p>Prerequisites</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><dl class="simple">
<dt>Learn how to create a classification</dt><dd><p>scheme for land cover land use
classification mapping.</p>
</dd>
</dl>
</td>
<td><p>None</p></td>
</tr>
</tbody>
</table>
<div class="section" id="part-1-specify-the-classification-scheme">
<h3>Part 1 Specify the classification scheme<a class="headerlink" href="#part-1-specify-the-classification-scheme" title="Permalink to this headline">¶</a></h3>
<p>“Classification scheme” is the name used to describe the land cover and land use classes adopted. It should cover all of the possible classes that occur in the area of interest. Here, you will create a classification scheme with detailed definitions of the land cover and land use classes to share with interpreters.</p>
<ol class="arabic simple">
<li><p>Create a decision tree for your land cover or land use classes. There may be one already in use by your department.  The tree should capture the most important classifications for your study. Here is an example:</p></li>
</ol>
<blockquote>
<div><ol class="loweralpha simple">
<li><p>This example includes a hierarchical component. For example, the green and red categories have multiple sub-categories, which might be multiple types of forest or crops or urban areas. You can also have classification schemes that are all one level with no hierarchical component.</p></li>
<li><p>For this Exercise, we’ll use a simplified land cover and land use classification as in the second image:</p></li>
</ol>
</div></blockquote>
<a class="reference internal image-reference" href="_images/land_cover_decision_tree.JPG"><img alt="Decision tree for land cover" class="align-center" src="_images/land_cover_decision_tree.JPG" style="width: 450px;" /></a>
<a class="reference internal image-reference" href="_images/classification_scheme.JPG"><img alt="The classification scheme we will use for this exercise, with two classes forest and non-forest" class="align-center" src="_images/classification_scheme.JPG" style="width: 450px;" /></a>
<ol class="arabic simple" start="2">
<li><p>When creating your own decision tree, be sure to specify if your classification scheme was derived from a template, including the IPCC land-use categories, CLC, or LUCAS.</p></li>
</ol>
<blockquote>
<div><ol class="loweralpha simple">
<li><p>If applicable, your classification scheme should be consistent with the national land cover and land use definitions.</p></li>
<li><p>In cases where the classification scheme definition is different from the national definition, you will need to provide a reason.</p></li>
</ol>
</div></blockquote>
<ol class="arabic simple" start="3">
<li><p>Create a detailed definition for each land cover and land use and change class included in the classification scheme. We recommend you include measurable thresholds.</p></li>
</ol>
<blockquote>
<div><ol class="loweralpha simple">
<li><p>Our classification will take place in Brazil, in an area of the Amazon rainforest undergoing deforestation.</p></li>
</ol>
<blockquote>
<div><ol class="lowerroman simple">
<li><p>We’ll define Forest as an area with over 70% tree cover.</p></li>
<li><p>We’ll define Non-forest as areas with less than 70% tree cover. This will capture urban areas, water, and agricultural fields.</p></li>
</ol>
</div></blockquote>
<ol class="loweralpha simple" start="2">
<li><p>For creating your own classifications, here’s some things to keep in mind:</p></li>
</ol>
<blockquote>
<div><ol class="lowerroman">
<li><p>It is important to have definitions for each of the classes. A lack of clear definitions of the land cover classes can make the quality of the resulting maps difficult to assess, and challenging for others to use. The definitions you come up with now will probably be working definitions that you find you need to modify as you move through the land cover classification process.</p>
<p>As you become more familiar with the landscape, data limitations, and the ability of the land cover classification methods to discriminate some classes better than others, you will undoubtedly need to update your definitions.</p>
</li>
<li><p>As you develop your definitions, you should be relating back to your applications. Make sure that your definitions meet your project objectives. For example, if you are creating a map to be used as part of your UNFCCC greenhouse gas reporting documents you will need to make sure that your definition of forest meets the needs of this application.</p>
<p>The above image is an excerpt of text from the Methods and Guidance from the Global Forest Observations Initiative (GFOI) document that describes the Intergovernmental Panel on Climate Change (IPCC) 2003 Good Practice Guidance (GPG) forest definition and suggestions to consider when drafting your forest definition. When creating your own decision tree, be sure to specify if your definitions follow a specific standard, e.g., using ISO standard Land Cover Meta-Language (LCML, ISO 19144-2) or similar.</p>
</li>
<li><p>During this online training course, you will be mapping land cover across the landscape using the Landsat composite, a moderate resolution data set. You may develop definitions based upon your knowledge from the field or from investigating high resolution imagery. However, when deriving your land cover class definitions, it’s also important to be aware of how the definitions relate to the data used to model the land cover.</p>
<p>You will continue to explore this relationship throughout the exercise. Will the spectral signatures between your land cover categories differ? If the spectral signatures are not substantially different between classes, is there additional data you can use to differentiate these categories? If not, you might consider modifying your definitions.</p>
</li>
</ol>
</div></blockquote>
</div></blockquote>
<p>More resources are available online, for example at <a class="reference external" href="http://www.ipcc.ch/ipccreports/tar/wg2/index.php?idp=132">http://www.ipcc.ch/ipccreports/tar/wg2/index.php?idp=132</a>.</p>
</div>
</div>
<div class="section" id="exercise-2-2-create-a-mosaic-for-classification">
<h2>Exercise 2.2. Create a mosaic for classification<a class="headerlink" href="#exercise-2-2-create-a-mosaic-for-classification" title="Permalink to this headline">¶</a></h2>
<p>We first need an image to classify before running a classification. For best results, we will need to create an optical mosaic with good coverage of our study area. We will build on knowledge gained in Module 1 to create an optical mosaic in SEPAL and retrieve it to Google Earth Engine.</p>
<p>In SEPAL you can run a classification on either a mosaic recipe or on a GEE asset. It is best practice to run a classification using an asset rather than on-the-fly with a recipe. This will improve how quickly your classification will export and avoid computational limitations.</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 60%" />
<col style="width: 40%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Objectives</p></th>
<th class="head"><p>Prerequisites</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Build on knowledge gained in Module 1.</p></td>
<td><p>SEPAL account</p></td>
</tr>
<tr class="row-odd"><td><p>Create a mosaic to be the basis for
your classification</p></td>
<td><p>Module 1</p></td>
</tr>
</tbody>
</table>
<div class="section" id="part-1-creating-and-exporting-a-mosaic-for-a-drawn-aoi">
<h3>Part 1. Creating and exporting a mosaic for a drawn AOI<a class="headerlink" href="#part-1-creating-and-exporting-a-mosaic-for-a-drawn-aoi" title="Permalink to this headline">¶</a></h3>
<p>We will create a mosaic for an area in the Amazon basin. If any of the steps for creating a mosaic are unfamiliar, please revisit Module 1, particularly Exercise 1.2.</p>
<ol class="arabic simple">
<li><p>Navigate to the Process tab, then create a new optical mosaic by selecting Optical Mosaic on the Process menu.</p></li>
<li><p>Under <strong>Area of Interest:</strong></p></li>
</ol>
<blockquote>
<div><ol class="loweralpha simple">
<li><p>Select <strong>Draw Polygon</strong> from the dropdown list.</p></li>
</ol>
</div></blockquote>
<img alt="A polygon drawn around the State of Rondônia" class="align-center" src="_images/rondonia.JPG" />
<ol class="arabic simple" start="3">
<li><p>Now use what you have learned in Module 1 to create a mosaic with imagery from the year 2019 (whole year or part of year, your choice). Don’t forget to consider which satellites you would like to include and which scenes you would like to include (all, some).</p></li>
<li><p>Your preview should include imagery data across your entire area of interest. This is important for your classification. Try also to get a cloud-free mosaic, as this makes your classification easier.</p></li>
<li><p>Name your mosaic for easy retrieval. Try “Module2_Amazon”.</p></li>
<li><p>When you’re satisfied with your mosaic, <strong>Retrieve</strong> it to Google Earth Engine. Be sure to include the red, green, blue, nir, swir1, and swir2 layers. You may choose to add the greenness, etc. layers as well.</p></li>
</ol>
</div>
<div class="section" id="part-2-finding-your-earth-engine-asset">
<h3>Part 2. Finding your Earth Engine Asset<a class="headerlink" href="#part-2-finding-your-earth-engine-asset" title="Permalink to this headline">¶</a></h3>
<p>For Exercise 2.3, you will need to know how to find your Earth Engine Asset.</p>
<ol class="arabic simple">
<li><p>Navigate to <a class="reference external" href="https://code.earthengine.google.com/">https://code.earthengine.google.com/</a> and login.</p></li>
<li><p>Navigate to your <strong>Assets</strong> tab in the left hand column.</p></li>
<li><p>Under <strong>Assets,</strong> look for the name of the mosaic you just exported.</p></li>
<li><p>Click on the mosaic name.</p></li>
<li><p>You will see a window with information about your mosaic pop up.</p></li>
<li><p>Click on the two overlapping box icon to copy your asset’s location.</p></li>
</ol>
<img alt="Your mosaic’s information pane." class="align-center" src="_images/mosaic_information.JPG" />
</div>
</div>
<div class="section" id="exercise-2-3-training-data-collection-in-ceo-sepal">
<h2>Exercise 2.3: Training data collection in CEO-SEPAL<a class="headerlink" href="#exercise-2-3-training-data-collection-in-ceo-sepal" title="Permalink to this headline">¶</a></h2>
<p>In this exercise, we will learn how to collect training data using the CEO-SEPAL tool. These training data points will become the foundation of our classification in Exercise 2.4. High quality training data is necessary to get good land cover map results. In the most ideal situation, training data is collected in the field by visiting each of the land cover types to be mapped and collecting attributes. When field collection is not an option, the second best choice is to digitize training data from high resolution imagery, or at the very least from the imagery to be classified.</p>
<p>In this assignment, you will create training data points using a combination of high-resolution imagery and the Landsat composite. These will be used to train the classifier in a supervised classification using SEPAL’s random forests algorithm. The goal of training the classifier is to provide examples of the variety of spectral signatures associated with each class in the map.</p>
<img alt="The CEO SEPAL interface" class="align-center" src="_images/ceo_sepal_interface.JPG" />
<table class="docutils align-default">
<colgroup>
<col style="width: 54%" />
<col style="width: 46%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Objectives</p></th>
<th class="head"><p>Prerequisites</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Create training data for your
classes that can be used to train a
machine learning algorithm.</p></td>
<td><p>SEPAL account</p></td>
</tr>
<tr class="row-odd"><td></td>
<td><p>Land cover categories defined
in Exercise 2.1.</p></td>
</tr>
<tr class="row-even"><td></td>
<td><p>Mosaic created in Exercise 2.2.</p></td>
</tr>
</tbody>
</table>
<div class="section" id="part-1-setting-up-a-training-project">
<h3>Part 1. Setting up a training project<a class="headerlink" href="#part-1-setting-up-a-training-project" title="Permalink to this headline">¶</a></h3>
<p>To collect training data, we will need to create a ceo-sepal project from within SEPAL. There are two ways to do this. The easier way is to begin the classification and follow a link when prompted. This is the approach we will use here.</p>
<p>However, you can also navigate to [<a class="reference external" href="https://sepal.io/ceo](https://sepal.io/ceo">https://sepal.io/ceo](https://sepal.io/ceo</a>), log in, and add a project directly through this interface (starting at Step 3a, below). If you use this route, you will need to create the classification later, using steps 1-3 below.</p>
<ol class="arabic simple">
<li><p>In the <strong>Process</strong> menu, click the green plus symbol and select <strong>Classification.</strong></p></li>
<li><p>Add the Amazon optical mosaic for classification:</p></li>
</ol>
<blockquote>
<div><ol class="loweralpha">
<li><p>Click <strong>+Add</strong> and choose <strong>Earth Engine Asset.</strong></p></li>
<li><p>Enter the Earth Engine Asset ID for the mosaic. The ID should look like “users/username/Module2_Amazon”.</p>
<p>Remember that you can find the link to your Earth Engine Asset ID via Google Earth Engine’s Asset tab (see Exercise 2.2 Part 2).</p>
</li>
<li><p>Select bands: Blue, Green, Red, NIR, SWIR1, &amp; SWIR2. You can add other bands as well if you included them in your mosaic.</p></li>
<li><p>Click <strong>Apply,</strong> then click <strong>Next.</strong></p></li>
</ol>
</div></blockquote>
<ol class="arabic simple" start="3">
<li><p>In the Training Data menu, click <a href="#id1"><span class="problematic" id="id2">**</span></a>Open training data collection tool.**This will open a new window/tab.</p></li>
</ol>
<img alt="Training data menu." class="align-center" src="_images/training_data_menu.JPG" />
<ol class="arabic simple" start="4">
<li><p>Click <strong>Add project.</strong></p></li>
<li><p>Type in a unique name for your training dataset, such as “Amazon training data”.</p></li>
<li><p>Use <strong>TRAINING DATA</strong> as the <strong>Type.</strong></p></li>
</ol>
<blockquote>
<div><ol class="loweralpha simple">
<li><p>The <strong>Training Data</strong> option enables you to create a project from scratch. To use this method, you will need to identify a set of land cover classes to classify (code list) and you will need to add imagery that will be used to identify the types of land cover. You will then manually place your training data on the map and classify them.</p></li>
<li><p><strong>CEP</strong> stands for Collect Earth Project and it contains a collection of training data points that have already been generated and just need to be classified based on the classes defined within the project. It typically contains a customized method for classifying training data that incorporates % cover.</p></li>
</ol>
</div></blockquote>
<ol class="arabic" start="7">
<li><p>Once you select the training data option, you will notice a new parameter: <strong>Scale (m).</strong> This scale refers to the spatial resolution of the imagery you will be classifying to create your map product. Type in 30, as that is the spatial resolution of Landsat. This will create a plot that is 30 m by 30 m.</p></li>
<li><p>Click the <strong>+</strong> button to the right of the section that says <strong>Code List.</strong> When you click the <strong>+</strong> button, an empty row is added to the Code List. You need two rows.</p>
<p>Add “Forest” and “Non Forest” to the Code List.</p>
</li>
</ol>
<a class="reference internal image-reference" href="_images/training_data_project_setup.JPG"><img alt="Training data project setup." class="align-center" src="_images/training_data_project_setup.JPG" style="width: 450px;" /></a>
<ol class="arabic simple" start="9">
<li><p>Add imagery to the CEO project by clicking on <strong>Add a layer.</strong> This is where you can select the background imagery you will use to collect the training data. You can add multiple different types of imagery, as well as different band combinations of the same imagery.</p></li>
</ol>
<blockquote>
<div><ol class="loweralpha simple">
<li><p>Select Google Earth Engine (Assets) from the drop down menu.</p></li>
</ol>
</div></blockquote>
<a class="reference internal image-reference" href="_images/add_imagery_layers.JPG"><img alt="Adding imagery layers." class="align-center" src="_images/add_imagery_layers.JPG" style="width: 450px;" /></a>
<ol class="arabic" start="10">
<li><p>Add your Earth Engine Asset mosaic. We will add a true-color set of bands first.</p>
<blockquote>
<div><ol class="loweralpha simple">
<li><p>Name your layer. Try ‘Landsat 8 RGB.’</p></li>
<li><p>Paste the link to your mosaic in GEE (see Part 2 in Exercise 2.2).</p></li>
<li><p>Type in ‘red, blue, and green’ for bands.</p></li>
<li><p>Use 0 and 3000 for min and max. You can alter these values slightly based on band min/max in the Landsat 8 satellite.</p></li>
</ol>
</div></blockquote>
</li>
<li><p>Add your Earth Engine Asset mosaic, but type in ‘swir1,nir,red’ to get SWIR, NIR, and red bands. Use a min and max of 300 and 3200.</p></li>
<li><p>You can also add additional band combinations. If you would like to add other versions of this mosaic with different band combinations, repeat steps 5-6, but use different bands and adjust the name according to the bands. For example, try NIR, red, green.</p></li>
<li><p>There are a number of other imagery options in the <strong>Add a layer</strong> drop down menu. Feel free to experiment with these.</p>
<p><strong>Digital Globe imagery no longer exists.</strong></p>
</li>
</ol>
<a class="reference internal image-reference" href="_images/GEE_asset_setup.JPG"><img alt="Google Earth Engine Asset setup" class="align-center" src="_images/GEE_asset_setup.JPG" style="width: 450px;" /></a>
<ol class="arabic" start="14">
<li><p>When you’ve set up the project, click on the <strong>Submit</strong> button.</p>
<p>Notice that the project is now listed. You can click edit if you want to adjust any of the settings for the project.</p>
</li>
</ol>
</div>
<div class="section" id="part-2-collect-training-data-points">
<h3>Part 2. Collect training data points<a class="headerlink" href="#part-2-collect-training-data-points" title="Permalink to this headline">¶</a></h3>
<p>Now that the CEO-SEPAL project is set up, you are ready to begin collecting data points for each land cover class. In most cases, it is ideal to collect a large amount of training data points for each class that capture the variability within each class and cover the different areas of the study area. However, for this exercise, you will only collect a small number of points: around 25 per class. When collecting data points, make sure that your plot contains only the land cover class of interest (no plots with a mixture of your land cover categories).</p>
<p>To help you understand why the random forest algorithm might get some categories you are trying to map confused with others, you will use spectral signatures charts in CEO-SEPAL to look at the NDVI signature of your different land cover classes. You should notice a few things when exploring the spectral signatures of your land cover classes. First, some classes are more spectrally distinct than others. For example, water is consistently dark in the NIR and MIR wavelengths, and much darker than the other classes. This means that it shouldn’t be difficult to separate water from the other land cover classes with high accuracy.</p>
<p>Second, not all pixels in the same classes have the exact same values—there is some natural variability! Looking at NDVI (and other vegetation indices) spectral signatures will help you begin to understand the inherent variability of your land cover classes. Capturing this variation will strongly influence the results of your classification.</p>
<ol class="arabic simple">
<li><p>First, let’s become familiar with the CEO-SEPAL Interface.</p></li>
</ol>
<blockquote>
<div><ol class="loweralpha simple">
<li><p>Click the blue <strong>collect</strong> button for the <strong>Amazon training data</strong> project.</p></li>
<li><p>You will immediately notice that a black and grey map appears on the screen. There are two drop down menus at the upper left and upper right of the map.</p></li>
</ol>
</div></blockquote>
<a class="reference internal image-reference" href="_images/ceo_sepal_data_collection.JPG"><img alt="The CEO SEPAL data collection interface." class="align-center" src="_images/ceo_sepal_data_collection.JPG" style="width: 450px;" /></a>
<ol class="arabic simple" start="2">
<li><p>In the upper left corner of the map, the <strong>SEPAL</strong> option is the default dark grey map. You can switch this to <strong>SATELLITE</strong> for satellite imagery.</p></li>
</ol>
<blockquote>
<div><ol class="loweralpha">
<li><p>In the upper right corner of the map, click the drop down menu that currently reads <strong>Default.</strong></p></li>
<li><p>Select <strong>LANDSAT 8 RGB,</strong> or the name of your RGB map.</p></li>
<li><p>Use the scroll wheel on your mouse to zoom in to the study area. You can click-hold and drag to pan around the map. Be careful though, as a single click will place a point on the map.</p>
<p>If you accidentally add a point, you can delete it by clicking on the red <strong>Delete</strong> button in the panel on the right.</p>
</li>
<li><p>Zoom in close to the imagery (until you can see individual pixels) so that you can see the amount of detail in this Landsat mosaic.</p></li>
<li><p>While zoomed in, click the image layer drop down and select <strong>Default.</strong> You should see a clear difference in spatial resolution between the 30-meter Landsat and the high-resolution (sub-meter) default Satellite imagery from Google (see below).</p></li>
</ol>
</div></blockquote>
<img alt="Mid resolution Landsat data and high resolution google imagery." class="align-center" src="_images/landsat_google_imagery.JPG" />
<ol class="arabic simple" start="3">
<li><p>Start collecting forest training data.</p></li>
</ol>
<blockquote>
<div><ol class="loweralpha">
<li><p>Next, zoom into an area that is clearly forested. When you find an area that is completely forested, click it once. Notice the information on the right side of the screen that popped up.</p></li>
<li><p>You have just placed a training data point!</p></li>
<li><p>Now you should switch back to the Landsat mosaic to make sure that this forested area is not covered with a cloud. This is a key step that you should do for every point you collect. If you mistakenly classify a cloudy pixel as Forest, then the results will be impacted negatively if your Landsat mosaic does have cloud-covered areas.</p></li>
<li><p>Once you are satisfied with your training point, click the <strong>Forest</strong> button on the right side of the screen to classify the point.</p>
<p>If you haven’t classified the point yet, then you can just click somewhere else on the map instead of deleting the record.</p>
</li>
</ol>
</div></blockquote>
<img alt="Collecting data in the CEO SEPAL interface." class="align-center" src="_images/ceo_sepal_collecting_data.JPG" />
<ol class="arabic simple" start="4">
<li><p>The information on the screen is then minimized and added to a row on the right side of the screen.</p></li>
</ol>
<blockquote>
<div><ol class="loweralpha simple">
<li><p>If you need to modify classification of any of your data points, you can click on the point ID to return to the classification (or delete) options.</p></li>
<li><p>You can click the <strong>Delete</strong> button if you are not satisfied with the placement of the point.</p></li>
</ol>
</div></blockquote>
<ol class="arabic" start="5">
<li><p>Now let’s click to create another ‘Forest’ point and use it to explore the <strong>Charts</strong> option.</p>
<p>There is a <strong>Charts</strong> drop down menu that allows you to look at the changes in spectral values over time at this point using a variety of spectral indices.</p>
</li>
</ol>
<blockquote>
<div><ol class="loweralpha simple">
<li><p><strong>Enhanced Vegetation Index (EVI):</strong> highlights areas of high biomass and is particularly responsive to variations in vegetation structure (as opposed to NDVI’s sensitivity to chlorophyll content).</p></li>
<li><p><strong>EVI2:</strong> a 2-band version of EVI.</p></li>
<li><p><strong>The Normalized Differenced Moisture Index (NDMI):</strong> estimates the amount of moisture in vegetation.</p></li>
<li><p><strong>The Normalized Differenced Vegetation Index (NDVI):</strong> a common vegetation index used to measure the amount of healthy, green vegetation in a given area. Forested pixels will typically have a NDVI value between 0.7 and 1.</p></li>
<li><p><strong>The Normalized Differenced Water Index (NDWI):</strong> highlights plant water content and is most commonly used to gauge plant water stress.</p></li>
</ol>
</div></blockquote>
<ol class="arabic simple" start="6">
<li><p>Click the <strong>Charts</strong> drop down menu and select <strong>NDVI.</strong> You should see a chart that looks similar to the below image.</p></li>
</ol>
<blockquote>
<div><ol class="loweralpha simple">
<li><p>This chart shows the NDVI values (derived from Landsat) of the pixel you selected for all dates where data is available. These time series charts are important when identifying seasonal (e.g., flooding or leaf senescence of deciduous trees) or permanent land cover changes.</p></li>
<li><p>The chart will take a minute or more to appear.</p></li>
<li><p>Notice that there is a lot more data available for more recent years, while there are only a few data points in the graph for years prior to 2000.</p></li>
<li><p>Place your mouse over the graph and move it from left to right. You’ll see that information on the acquisition date and an NDVI value pops up for each data point.</p></li>
<li><p>Zoom into a temporal subset to see seasonal differences in NDVI values. Click on the chart near the year 2013 and drag it to the right to highlight a year or two worth of data. Release the click. Now you will see the chart has been zoomed into that subset time range making the data trends easier to read.</p></li>
</ol>
<blockquote>
<div><ol class="lowerroman simple">
<li><p>Note that the Y-axis will scale to the range of values for the available data. Keep an eye on the Y-axis when analyzing different spectral signatures.</p></li>
<li><p>Click the <strong>Reset zoom</strong> button to return to the full time series view.</p></li>
<li><p>To close the chart, click anywhere outside of the chart.</p></li>
</ol>
</div></blockquote>
</div></blockquote>
<img alt="NDVI time series information." class="align-center" src="_images/NDVI.JPG" />
<ol class="arabic" start="6">
<li><p>Explore some of the other vegetation or water indices using the Charts drop down.</p>
<p>When you are done, click the <strong>Forest</strong> button again to close the class selection options.</p>
</li>
<li><p>Begin collecting the rest of the 25 <strong>Forest</strong> training data points throughout other parts of the study area.</p></li>
</ol>
<blockquote>
<div><ol class="loweralpha simple">
<li><p>The study area contains an abundance of forested land, so it should be pretty easy to identify places that can be confidently classified as forest. If you’d like, use the charts function to ensure that there is a relatively high NDVI value for the point.</p></li>
<li><p>Continue to switch back and forth between the Landsat mosaic and the base <strong>Satellite</strong> imagery to ensure that:</p></li>
</ol>
<blockquote>
<div><ol class="lowerroman simple">
<li><p>you are placing data points within the extent of the mosaic and</p></li>
<li><p>that you aren’t placing a point over a cloud in the mosaic.</p></li>
</ol>
</div></blockquote>
<ol class="loweralpha simple" start="3">
<li><p>You will notice that the quality of the base <strong>Satellite</strong> imagery varies. This is where the charts can come in particularly handy. You may also find it useful to zoom out and zoom back in, as the imagery changes based on your zoom scale. The images below show the same general area, but at slightly different zoom scales.</p></li>
</ol>
</div></blockquote>
<img alt="Collecting training data in the CEO SEPAL interface." class="align-center" src="_images/collect_training_data.JPG" />
<ol class="arabic" start="8">
<li><p>Collect about 25 points for the <strong>Forest</strong> land cover class.</p>
<p>When you are done, zoom out to the full extent of the Amazon Landsat 8 image. Did you place data points somewhat equally across the full region? Are all points clustered in the same region? It’s best to make sure you have data points covering the full spatial extent of the study region, add more points in areas that are sparsely represented if needed.</p>
</li>
<li><p>Once you are satisfied with your array of forested training data points, move on to the <strong>Non-Forest</strong> training points.</p></li>
</ol>
<blockquote>
<div><ol class="loweralpha simple">
<li><p>Since we are using a very basic set of land cover classes for this exercise, this should include agricultural areas, water, and buildings and roads. Therefore, it will be important that you focus on collecting a variety of points from different types of land cover throughout the study area.</p></li>
<li><p><strong>Water</strong> is one of the easiest classes to identify and the easiest to model, due to the distinct spectral signature of water.</p></li>
</ol>
<blockquote>
<div><ol class="lowerroman simple">
<li><p>Look for water bodies within your Landsat image. On your <strong>Landsat 8 SWIR</strong> image, they will appear black.</p></li>
<li><p>Collect 10-15 data points for Water and be sure to spread them throughout Lake Mai Ndombe, the water sources feeding into it, and a couple of the water bodies/rivers to the eastern side of the mosaic. Be sure to put 2-3 points on rivers.</p></li>
<li><p>Look at the Chart of NDWI and NDVI to see if the points you are classifying are covered in water year-round.</p></li>
<li><p>The spectral signature for water will be relatively low (0-0.4) when looking at the NDVI chart.</p></li>
<li><p>Some wetland areas may have varying amounts of water throughout the year, so it is important to check the time series charts. If you encounter areas that look like water but have seasonally high NDVI, place your point in a different area that has a more distinct water signature. It is ideal to give the classifier points that are homogenous and unambiguous.</p></li>
</ol>
</div></blockquote>
</div></blockquote>
<img alt="Collecting data points in water." class="align-center" src="_images/data_points_water.JPG" />
<ol class="arabic simple" start="10">
<li><p>Let’s now collect some building and road non-forest Training Data.</p></li>
</ol>
<blockquote>
<div><ol class="loweralpha simple">
<li><p>There are not very many residential areas in the region. However, if you look you can find homes with dirt roads, and there are some airports as well.</p></li>
<li><p>Place a point or points within these areas and classify them as Non-forest. Do your best to avoid placing the points over areas of the town with lots of trees.</p></li>
<li><p>Find some roads, and place points and classify as Non-forest. These may look like areas of bare soil. Both bare soil and roads are classified as Non-forest, so place some points on both.</p></li>
</ol>
</div></blockquote>
<a class="reference internal image-reference" href="_images/data_points_residential.JPG"><img alt="Collecting residential and other human settlement area datapoints." class="align-center" src="_images/data_points_residential.JPG" style="width: 450px;" /></a>
<ol class="arabic simple" start="11">
<li><p>Next, place several points in grassland/pasture, shrub, and agricultural areas around the study area.</p></li>
</ol>
<blockquote>
<div><ol class="loweralpha simple">
<li><p>As you’ve done before, look at the NDVI signature of the points you place before you actually classify them. Grasslands may have NDVI values between 0.4 and 0.6, sometimes a little higher.</p></li>
<li><p>Shrubs or small, non-forest vegetation can sometimes be hard to identify, even with high-resolution imagery. Do your best to find vegetation that is clearly not forest. The NDVI signature of shrubs may be relatively high (0.6-0.8).</p></li>
<li><p>The texture of the vegetation is one of the best ways to differentiate between trees and grasses/shrubs. Look at the below image and notice the clear contrast between the area where the points are placed and the other areas in the image that have rougher textures and that create shadows.</p></li>
</ol>
</div></blockquote>
<a class="reference internal image-reference" href="_images/low_vegetation_data.JPG"><img alt="Collecting low vegetation data" class="align-center" src="_images/low_vegetation_data.JPG" style="width: 450px;" /></a>
<a class="reference internal image-reference" href="_images/low_vegetation_data_2.JPG"><img alt="Collecting low vegetation data." class="align-center" src="_images/low_vegetation_data_2.JPG" style="width: 450px;" /></a>
<ol class="arabic simple" start="12">
<li><p>Now collect <strong>cloud</strong> training data in the <strong>Non-forest</strong> class, if your Landsat has any clouds.</p></li>
</ol>
<blockquote>
<div><ol class="loweralpha simple">
<li><p>If there are some clouds that were not removed during the Landsat mosaic creation process you will need to create training data for the clouds that remain so that the classifier knows what those pixels represent.</p></li>
<li><p>Turn on the Landsat mosaic imagery and navigate to some distinct areas with clouds. Click to place additional <strong>Non-forest</strong> points.</p></li>
<li><p>Pan around other parts of the mosaic and classify the clouds that you find. Ensure that the point you place only contains clouds and excludes any amount of vegetation. As you did with other classes, try and collect points in all parts of the study area.</p></li>
<li><p>Sometimes clouds were detected during the mosaic process and were mostly removed. However, you can see some of the edges of those clouds remain.</p></li>
<li><p>Note that you may not have any clouds in your Landsat imagery.</p></li>
</ol>
</div></blockquote>
<a class="reference internal image-reference" href="_images/cloud_data.JPG"><img alt="Collecting cloud data." class="align-center" src="_images/cloud_data.JPG" style="width: 450px;" /></a>
<ol class="arabic simple" start="13">
<li><p>Continue collecting Non-forest points. Again, be sure to spread the points out across the study area.</p></li>
<li><p>Once again when you are done collecting data for these categories, zoom out to the full extent of the study region (Amazon Landsat 8 RGB data layer).</p></li>
</ol>
<blockquote>
<div><ol class="loweralpha simple">
<li><p>Did you place data points somewhat equally across the full region?</p></li>
<li><p>Are all points clustered in the same region?</p></li>
<li><p>It’s best to make sure you have data points covering the full spatial extent of the study region, add more points in areas that are sparsely represented if needed.</p></li>
</ol>
</div></blockquote>
<ol class="arabic simple" start="15">
<li><p>When you are done collecting your training data, scroll through the list of training data that you have collected. Note that the number in parenthesis is the code that corresponds to the land cover type.</p></li>
</ol>
<blockquote>
<div><p>1=Forest</p>
<p>2=Non-Forest</p>
</div></blockquote>
</div>
<div class="section" id="part-3-export-data-as-csv">
<h3>Part 3. Export data As CSV<a class="headerlink" href="#part-3-export-data-as-csv" title="Permalink to this headline">¶</a></h3>
<p>Now we will download the training data we have collected.</p>
<ol class="arabic simple">
<li><p>Above your training data points you will see a blue Download CSV button.</p></li>
</ol>
<a class="reference internal image-reference" href="_images/training_data_points.JPG"><img alt="Training data points." class="align-center" src="_images/training_data_points.JPG" style="width: 450px;" /></a>
<ol class="arabic simple" start="2">
<li><p>Click the CSV button to download the reference data as a comma separated values format.</p></li>
</ol>
<blockquote>
<div><ol class="loweralpha simple">
<li><p>You will either be prompted by your browser to choose a location to save the data to.</p></li>
<li><p>Or the data will be automatically downloaded to the folder your browser uses for downloads, usually your Downloads folder.</p></li>
</ol>
</div></blockquote>
<ol class="arabic" start="3">
<li><p>Once downloaded, examine your data by opening it in an application which can view tables, such as Microsoft Excel.</p>
<p>There are 4 different columns in the table:</p>
</li>
</ol>
<blockquote>
<div><ol class="loweralpha simple">
<li><p>id—this is the same unique ID that you can see on the right side of the CEO-SEPAL interface.</p></li>
<li><p>YCoordinate and XCoordinate—locational information for all of the training data (in the WGS 84, EPSG 4326, coordinate reference system).</p></li>
<li><p>class—land cover class in integer form. Again, 1=Forest and 2=Non-Forest.</p></li>
</ol>
</div></blockquote>
<a class="reference internal image-reference" href="_images/sample_training_data.JPG"><img alt="A sample training data file." class="align-center" src="_images/sample_training_data.JPG" style="width: 450px;" /></a>
</div>
<div class="section" id="part-4-uploading-your-csv-to-google-earth-engine">
<h3>Part 4. Uploading your CSV to Google Earth Engine<a class="headerlink" href="#part-4-uploading-your-csv-to-google-earth-engine" title="Permalink to this headline">¶</a></h3>
<p>With all your training data points collected, you will now need to upload the data into Google Earth Engine to use it for classification.</p>
<ol class="arabic simple">
<li><p>To use this data in SEPAL, you need to first upload it into Google Earth Engine.</p></li>
</ol>
<blockquote>
<div><ol class="loweralpha simple">
<li><p>Navigate to [<a class="reference external" href="https://code.earthengine.google.com/](https://code.earthengine.google.com/">https://code.earthengine.google.com/](https://code.earthengine.google.com/</a>)</p></li>
<li><p>Log into GEE using your account and then navigate to the Assets tab.</p></li>
<li><p>Click <strong>New.</strong></p></li>
<li><p>Select <strong>CSV file (.csv)</strong> under the <strong>Table Upload</strong> section.</p></li>
</ol>
</div></blockquote>
<a class="reference internal image-reference" href="_images/GEE_asset_upload.JPG"><img alt="The Google Earth Engine interface for uploading assets." class="align-center" src="_images/GEE_asset_upload.JPG" style="width: 450px;" /></a>
<ol class="arabic simple" start="2">
<li><p>In the new window that pops up, fill in the requested information.</p></li>
</ol>
<blockquote>
<div><ol class="loweralpha simple">
<li><p>Select your <strong>CSV file</strong> from your local machine.</p></li>
<li><p>Optionally, <strong>rename</strong> the asset.</p></li>
<li><p>Choose the <strong>asset id path.</strong> This is the where the asset will be saved once uploaded</p></li>
<li><p>Add XCoordinate and YCoordinate to the Advanced options <strong>X column and Y columns.</strong></p></li>
</ol>
</div></blockquote>
<ol class="arabic" start="3">
<li><p>Click Upload to initiate the upload.</p>
<p>You may need to rename your csv if the filename has spaces. Do this in your computer’s file system and try again.</p>
</li>
<li><p>After a few minutes your upload should be complete!</p></li>
</ol>
<blockquote>
<div><ol class="loweralpha simple">
<li><p>Check the path where you uploaded your asset to confirm it has successfully uploaded.</p></li>
<li><p>Click on the file name.</p></li>
<li><p>Make note of your <strong>TableID,</strong> which you will need for Exercise 2.4.</p></li>
</ol>
</div></blockquote>
<a class="reference internal image-reference" href="_images/info_page_table_id.JPG"><img alt="The information page with your table id." class="align-center" src="_images/info_page_table_id.JPG" style="width: 450px;" /></a>
<p><strong>Congratulations! You have successfully completed this exercise. You now know how to use SEPAL’s version of Collect Earth Online to create training data for a supervised classification.</strong></p>
</div>
</div>
<div class="section" id="exercise-2-4-classification-using-machine-learning-algorithms-random-forests-in-sepal">
<h2>Exercise 2.4. Classification using machine learning algorithms (Random Forests) in SEPAL<a class="headerlink" href="#exercise-2-4-classification-using-machine-learning-algorithms-random-forests-in-sepal" title="Permalink to this headline">¶</a></h2>
<img alt="The outcome of a random forest model." class="align-center" src="_images/random_forest_model_outcome.JPG" />
<p>As mentioned in the Module introduction, the classification algorithm you will be using today is called random forest.  The random forest algorithm creates numerous decision trees for each pixel. Each of these decision trees votes on what the pixel should be classified as. The land cover class that receives the most votes is then assigned as the map class for that pixel. Random forests are efficient on large data and accurate when compared to other classification algorithms.</p>
<p>To complete the classification of our mosaicked image you are going to use a random forests classifier contained within the easy-to-use Classification tool in SEPAL. The image values used to train the model include the Landsat mosaic values and some derivatives (such as NDVI). There are likely additional data sets that can be used to help differentiate land cover classes, such as elevational data. If that is the case, it would be good to load this into the project and include them in the model. Examples of additional data sets that would probably be quite helpful to differentiate classes include climatic and topographic (aspect, elevation) information.</p>
<p>After we create the map, you might find that there are some areas that are not classifying well. The classification process is iterative, and there are ways you can modify the process to get better results. One way is to collect more or better reference data to train the model. You can test different classification algorithms, explore object based approaches opposed to pixel based approaches, or be more creative with specifying the model predictor variables. In the case of being more creative with model predictor variables you can try using multiple dates of data (instead of a single date), or try using texture bands. The possibilities are many and should relate back to the nature of the classes you hope to map. Last but certainly not least is to improve the quality of your training data. Be sure to log all of these decision points in order to recreate your analysis in the future.</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 53%" />
<col style="width: 47%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Objectives</p></th>
<th class="head"><p>Prerequisites</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Run SEPAL’s classification tool.</p></td>
<td><p>SEPAL account</p></td>
</tr>
<tr class="row-odd"><td></td>
<td><p>Land cover categories defined in
Exercise 2.1.</p></td>
</tr>
<tr class="row-even"><td></td>
<td><p>Mosaic created in Exercise 2.2.</p></td>
</tr>
<tr class="row-odd"><td></td>
<td><p>Training data created in Exercise
2.3.</p></td>
</tr>
</tbody>
</table>
<div class="section" id="part-0-merging-asset-tables-optional">
<h3>Part 0. Merging Asset Tables (Optional)<a class="headerlink" href="#part-0-merging-asset-tables-optional" title="Permalink to this headline">¶</a></h3>
<p>To get a more accurate training dataset, consider combining multiple training datasets. For example, if you’re completing these exercises as part of a group training, try combining your training data set with your neighbors’. We will show you how to do this using your .csv files, however if you are more familiar with GEE you can also combine files using code in GEE.</p>
<ol class="arabic simple">
<li><p>Navigate to your GEE table information as in Exercise 2.3 Part 4.</p></li>
<li><p>Click on Share.</p></li>
</ol>
<a class="reference internal image-reference" href="_images/info_page_table_id.JPG"><img alt="The GEE table information where you can find your asset table id." class="align-center" src="_images/info_page_table_id.JPG" style="width: 450px;" /></a>
<a class="reference internal image-reference" href="_images/share_asset_table.JPG"><img alt="The sharing interface for your asset table" class="align-center" src="_images/share_asset_table.JPG" style="width: 450px;" /></a>
<ol class="arabic simple" start="3">
<li><p>Fill in your neighbor’s email address, set them as a <strong>Reader</strong> or <strong>Writer,</strong> and click <strong>Add.</strong></p></li>
<li><p>Now copy the link and email it to your neighbor. Ask them to send you the link to their table.</p></li>
<li><p>Once you have their table’s address, click the table link that you were sent.</p></li>
</ol>
<blockquote>
<div><ol class="loweralpha simple">
<li><p>Download the fusion table as a CSV just as you did with your own.</p></li>
<li><p>Once you have your and their CSVs downloaded, open them in Microsoft Excel.</p></li>
<li><p>Copy and paste the contents of your neighbor’s CSV to your own training data CSV.</p></li>
</ol>
<blockquote>
<div><ol class="lowerroman simple">
<li><p>Do not include their column header.</p></li>
<li><p>Only copy and paste the data.</p></li>
</ol>
</div></blockquote>
<ol class="loweralpha simple" start="4">
<li><p>Save the CSV to your desired location and give it a unique name.</p></li>
</ol>
</div></blockquote>
</div>
<div class="section" id="part-1-run-supervised-classification-in-sepal">
<h3>Part 1. Run supervised classification in SEPAL<a class="headerlink" href="#part-1-run-supervised-classification-in-sepal" title="Permalink to this headline">¶</a></h3>
<ol class="arabic simple">
<li><p>Ideally, your original classification output is still open in a separate tab. If so, navigate back to it and skip to Step 3.</p></li>
<li><p>If your window is not still open, navigate to SEPAL by clicking this link [<a class="reference external" href="https://sepal.io/](https://sepal.io/">https://sepal.io/](https://sepal.io/</a>).</p></li>
</ol>
<blockquote>
<div><ol class="loweralpha simple">
<li><p>In the <strong>Process</strong> menu, click the green plus symbol and select Classification.</p></li>
<li><p>Add the Amazon optical mosaic for classification:</p></li>
</ol>
<blockquote>
<div><ol class="lowerroman simple">
<li><p>Click <strong>Add</strong> and choose <strong>Earth Engine Asset</strong></p></li>
<li><p>Enter the Earth Engine Asset ID for the mosaic. The ID should look like “users/username/Module2_Amazon”</p></li>
<li><p>Remember that you can find the link to your Earth Engine Asset ID via Google Earth Engine’s Asset tab (see Exercise 2.2 Part 2).</p></li>
<li><p>Select bands: Blue, Green, Red, NIR, SWIR1, &amp; SWIR2. You can add other bands as well if you included them in your mosaic.</p></li>
<li><p>Click <strong>Apply,</strong> then click <strong>Next.</strong></p></li>
</ol>
</div></blockquote>
</div></blockquote>
<ol class="arabic simple" start="3">
<li><p>Now, we’ll add the Training Data we collected in Exercise 2.3 in the <strong>TRN tab.</strong></p></li>
</ol>
<blockquote>
<div><ol class="loweralpha simple">
<li><p>Enter the path to your Earth Engine asset in the EE Table ID field.</p></li>
<li><p>In the <strong>Class Column</strong> field select the column name that is associated with the class. In our example this should be ‘class’.</p></li>
<li><p>Click <strong>Done.</strong></p></li>
</ol>
</div></blockquote>
<a class="reference internal image-reference" href="_images/training_data_menu_2.JPG"><img alt="The training data menu." class="align-center" src="_images/training_data_menu_2.JPG" style="width: 450px;" /></a>
<ol class="arabic simple" start="4">
<li><p>Now a preview will load.</p></li>
<li><p>Click on <strong>AUX</strong> to examine the auxiliary data sources available for the classification.</p></li>
</ol>
<blockquote>
<div><ol class="loweralpha simple">
<li><p>Auxiliary inputs are optional layers which can be added to help aid the classification. There are three additional sources available: Latitude - Includes the latitude of each pixel; Terrain - Includes elevation of each pixel from SRTM data; Water - Includes information from the JRC Global Surface water Mapping layers.</p></li>
<li><p>Click on <strong>Water.</strong></p></li>
<li><p>Click <strong>Apply.</strong></p></li>
</ol>
</div></blockquote>
<ol class="arabic simple" start="6">
<li><p>Again, after a few seconds, a preview of the classification will load.</p></li>
</ol>
<blockquote>
<div><ol class="loweralpha simple">
<li><p>Your classified map may look different than the example land cover map shown below.</p></li>
<li><p>Depending on the training data you collected, your classes may be substantially different.</p></li>
<li><p>The quality of the output map is also dependent on the quality of the mosaic.</p></li>
</ol>
</div></blockquote>
<img alt="The classification preview screen." class="align-center" src="_images/classification_preview.JPG" />
<ol class="arabic simple" start="7">
<li><p>Now we’ll save our classification output.</p></li>
</ol>
<blockquote>
<div><ol class="loweralpha simple">
<li><p>First, rename your classification by typing a new name in the tab.</p></li>
<li><p>Click <strong>Retrieve classification</strong> in the upper right hand corner (cloud icon).</p></li>
<li><p>Choose 30 m resolution.</p></li>
<li><p>Retrieve as either a <strong>Google Earth Engine Asset</strong> or to your <strong>SEPAL Workspace.</strong> Choose to export to a GEE Asset if you would like to be able to share your results or perform additional analysis in GEE. Otherwise, export to your SEPAL workspace (recommended here for ease of use).</p></li>
<li><p>Once the download begins, you will see the spinning wheel in the bottom left of the webpage in <strong>Tasks.</strong> Click the spinning wheel to observe the progress of your download.</p></li>
<li><p>When complete, if you chose GEE Asset the file will be in your GEE Assets. If you chose SEPAL workspace, the file will be in your SEPAL downloads folder. (Browse &gt; downloads &gt; classification folder).</p></li>
</ol>
</div></blockquote>
<a class="reference internal image-reference" href="_images/retrieval_interface.JPG"><img alt="The retrieval interface." class="align-center" src="_images/retrieval_interface.JPG" style="width: 450px;" /></a>
</div>
<div class="section" id="part-2-qa-qc-considerations-and-methods">
<h3>Part 2. QA/QC considerations and methods<a class="headerlink" href="#part-2-qa-qc-considerations-and-methods" title="Permalink to this headline">¶</a></h3>
<p>Quality assurance and quality control, commonly referred to as QA/QC, is a critical part of any analysis. There are two approaches to QA/QC: formal and informal. Formal QA/QC, specifically sample-based estimates of error and area are described in Module 4. Informal QA/QC involves qualitative approaches to identifying problems with your analysis and classifications to iterate and create improved classifications. Here we’ll discuss one approach to informal QA/QC.</p>
<p>Following analysis you should spend some time looking at your change detection in order to understand if the results make sense. We’ll do this by adding your classification to the SEPAL-CEO project we created in Part 2. This allows us to visualize the data and collect additional training points if we find areas of poor classification. Other approaches not covered here include visualizing the data in Google Earth Engine or in another program, such as QGIS or ArcMAP.</p>
<ol class="arabic simple">
<li><p>Check your Google Earth Engine Assets for your retrieved Amazon Classification map. Copy the <strong>Image ID</strong> link.</p></li>
<li><p>Navigate back to your SEPAL-CEO project at <a class="reference external" href="https://sepal.io/ceo/">https://sepal.io/ceo/</a>.</p></li>
</ol>
<blockquote>
<div><ol class="loweralpha simple">
<li><p>Next to your Amazon project, click on <strong>Edit.</strong></p></li>
<li><p>Add a <strong>new layer,</strong> title it <strong>Classification,</strong> and add the information from your Google Earth Engine classification asset. You have two classes, so your Min should be 1, Max 2, and Bands ‘class’.</p></li>
<li><p>Click <strong>Submit.</strong></p></li>
</ol>
</div></blockquote>
<a class="reference internal image-reference" href="_images/GEE_asset.JPG"><img alt="The Google Earth Engine Asset." class="align-center" src="_images/GEE_asset.JPG" style="width: 450px;" /></a>
<ol class="arabic simple" start="3">
<li><p>Now click Collect for your Amazon project.</p></li>
<li><p>Switch the imagery to your Classification and pan and zoom around the map. Black will be ‘Forest,’ and white is ‘Non-forest’ pixels.</p></li>
<li><p>Compare your Classification map to Landsat 8 imagery.</p></li>
</ol>
<blockquote>
<div><ol class="loweralpha simple">
<li><p>What land cover was classified correctly?</p></li>
<li><p>Where do you see errors on the map?</p></li>
<li><p>What classes seem to have the most error?</p></li>
<li><p>What do you think may have caused one class to be classified more accurately than another?</p></li>
</ol>
</div></blockquote>
<ol class="arabic simple" start="6">
<li><p>If your results make sense, and you are happy with them, great! Go on to the formal QA/QC in Module 4.</p></li>
<li><p>However if you are not satisfied, collect additional points of training data where you see inaccuracies following the same process as in Exercise 2.3. Then re-run the classification following the steps in Part 1.</p></li>
</ol>
<p><strong>Congratulations! You now know how to produce map classifications in SEPAL.</strong></p>
</div>
</div>
</div>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="index.html">SEPAL-CEO Area Estimation</a></h1>








<h3>Navigation</h3>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="intro.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="module-1.html">Module 1. Mosaic image generation</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Module 2. Image classification</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#exercise-2-1-response-design-for-classification">Exercise 2.1. Response design for classification</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#part-1-specify-the-classification-scheme">Part 1 Specify the classification scheme</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#exercise-2-2-create-a-mosaic-for-classification">Exercise 2.2. Create a mosaic for classification</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#part-1-creating-and-exporting-a-mosaic-for-a-drawn-aoi">Part 1. Creating and exporting a mosaic for a drawn AOI</a></li>
<li class="toctree-l3"><a class="reference internal" href="#part-2-finding-your-earth-engine-asset">Part 2. Finding your Earth Engine Asset</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#exercise-2-3-training-data-collection-in-ceo-sepal">Exercise 2.3: Training data collection in CEO-SEPAL</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#part-1-setting-up-a-training-project">Part 1. Setting up a training project</a></li>
<li class="toctree-l3"><a class="reference internal" href="#part-2-collect-training-data-points">Part 2. Collect training data points</a></li>
<li class="toctree-l3"><a class="reference internal" href="#part-3-export-data-as-csv">Part 3. Export data As CSV</a></li>
<li class="toctree-l3"><a class="reference internal" href="#part-4-uploading-your-csv-to-google-earth-engine">Part 4. Uploading your CSV to Google Earth Engine</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#exercise-2-4-classification-using-machine-learning-algorithms-random-forests-in-sepal">Exercise 2.4. Classification using machine learning algorithms (Random Forests) in SEPAL</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#part-0-merging-asset-tables-optional">Part 0. Merging Asset Tables (Optional)</a></li>
<li class="toctree-l3"><a class="reference internal" href="#part-1-run-supervised-classification-in-sepal">Part 1. Run supervised classification in SEPAL</a></li>
<li class="toctree-l3"><a class="reference internal" href="#part-2-qa-qc-considerations-and-methods">Part 2. QA/QC considerations and methods</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="module-5.html">```</a></li>
<li class="toctree-l1"><a class="reference internal" href="module-5.html#user-defined-variables">// User defined variables               ///</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="index.html">Documentation overview</a><ul>
      <li>Previous: <a href="module-1.html" title="previous chapter">Module 1. Mosaic image generation</a></li>
      <li>Next: <a href="module-3.html" title="next chapter">&lt;no title&gt;</a></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2021, Karen Dyson, Karis Tenneson.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 3.5.1</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
      |
      <a href="_sources/module-2.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>